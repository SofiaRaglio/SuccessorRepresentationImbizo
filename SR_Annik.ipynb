{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy.spatial as spatial\n",
    "import scipy.stats as stats\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self, rows=20, cols=20, rewards={(5,5):10},\n",
    "                 env_type=None, rho=0.0, step_penalization=-0.01,\n",
    "                 terminals=None, obstacles=None, jumps=None,\n",
    "                 port_shift=None, barheight=None,\n",
    "                 around_reward=False,\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        :param rows (int): specifying width (x dim) of grid\n",
    "        :param cols (int): specifying height (y dim) of grid\n",
    "        :param rewards (dict): reward location coordinates as keys and reward magnitude as values\n",
    "\n",
    "        :param env_type (str): [None, 'bar','room','tmaze', 'triple_reward']\n",
    "        :param rho (float): density of obstacles to be randomly positioned in environment\n",
    "        :param step_penalization (float): penalization for each step (small negative reward)\n",
    "\n",
    "        :param terminals (list): terminal state coordinates\n",
    "        :param obstacles (list): obstacle coordinates\n",
    "        :param jumps (dict): keys and values are coordinates in the environment (x,y):(w,z)\n",
    "                             where agent can select jump action in coordinate (x,y) and moves to coordinate (w,z)\n",
    "\n",
    "        :param port_shift (str):  ['equal', 'left', 'right']: type of probability distribution for Kirth's task\n",
    "        :param barheight (int): height of horizontal line of obstacles dividing the plane\n",
    "\n",
    "        :param around_reward (bool): whether to randomly choose agent starting location around reward location\n",
    "        '''\n",
    "        self.shape = (rows, cols)\n",
    "        self.c = cols\n",
    "        self.r = rows\n",
    "\n",
    "        self.maze_type = env_type\n",
    "        self.rho = rho\n",
    "\n",
    "        # basic set up states, rewards\n",
    "        self.nstates = self.c*self.r\n",
    "        self.rewards = rewards\n",
    "\n",
    "        # populate list of obstacles\n",
    "        self.obstacles_list = obstacles\n",
    "\n",
    "        if self.maze_type == 'bar':\n",
    "            if barheight is not None:\n",
    "                self.barheight \t= barheight\n",
    "        self.grid, self.useable, self.obstacles_list = self.buildGrid()\n",
    "\n",
    "        # populate list of terminals\n",
    "        if terminals is not None:\n",
    "            if isinstance(terminals, tuple):\n",
    "                self.terminal2D = [terminals]\n",
    "                self.terminal = [self.twoD2oneD(terminals)]\n",
    "            else:\n",
    "                self.terminal2D = terminals\n",
    "                self.terminal = [self.twoD2oneD((r,c)) for r,c in terminals]\n",
    "        else:\n",
    "            self.terminal2D = []\n",
    "            self.terminal = []\n",
    "\n",
    "        # populate list of jump states\n",
    "        if jumps is not None:\n",
    "            self.jump = jumps\n",
    "            self.jump_from = [self.twoD2oneD((r,c)) for r,c in list(jumps.keys())]\n",
    "            self.jump_to = [self.twoD2oneD((r,c)) for r,c in list(jumps.values())]\n",
    "        else:\n",
    "            self.jump = None\n",
    "            self.jump_from = []\n",
    "            self.jump_to = []\n",
    "\n",
    "        # Actions\n",
    "        self.action_list    = kwargs.get('actionlist', ['Down', 'Up', 'Right', 'Left', 'Jump', 'Poke'])\n",
    "        self.action_dict    = kwargs.get('actiondict', {x: ind for ind, x in enumerate([x[0] for x in self.action_list])})\n",
    "        self.nactions       = len(self.action_list)\n",
    "        self.buildTransitionMatrix()\n",
    "\n",
    "        # Reward\n",
    "        self.finish_after_first_reward = kwargs.get('finish_after_first_reward',True)\n",
    "        if self.finish_after_first_reward:\n",
    "            # add reward location to list of terminal states\n",
    "            for r,c in self.rewards.keys():\n",
    "                self.terminal2D.append((r,c))\n",
    "                self.terminal.append(self.twoD2oneD((r, c)))\n",
    "        self.rwd_action = kwargs.get('rewarded_action', 'Poke')\n",
    "        self.step_penalization = step_penalization\n",
    "        self.buildRewardFunction()\n",
    "\n",
    "        # additional features from specific environment types\n",
    "        if self.maze_type == 'tmaze':\n",
    "            if port_shift is not None:\n",
    "                self.port_shift\t= port_shift\n",
    "            else:\n",
    "                self.port_shift = 'none'\n",
    "        if self.maze_type == 'triple_reward':\n",
    "            self.rwd_loc \t\t= [(self.r-1, 0), (self.r-1, self.c-1), (0, self.c-1)]\n",
    "            self.orig_rwd_loc \t= [(self.r-1, 0), (self.r-1, self.c-1), (0, self.c-1)]\n",
    "            self.starter \t\t= kwargs.get('t_r_start', (0,0))\n",
    "            self.start_loc      = self.starter\n",
    "\n",
    "        self.random_start = kwargs.get('random_start',True)\n",
    "        self.reset()\n",
    "        \n",
    "        self.view = True\n",
    "        if self.view:\n",
    "            view_labels = kwargs.get('view_labels',False)\n",
    "            self.reset_viewer(states=view_labels)\n",
    "            self.viewer = self.figure[0].canvas\n",
    "\n",
    "    def oneD2twoD(self, idx):\n",
    "        return (int(idx / self.shape[1]),np.mod(idx,self.shape[1]))\n",
    "\n",
    "    def twoD2oneD(self, coord_tuple):\n",
    "        r,c = coord_tuple\n",
    "        return (r * self.shape[1]) + c\n",
    "\n",
    "    def buildGrid(self, bound=False): #formerly grid_maker()\n",
    "        env_types = [None, 'bar','room','tmaze', 'triple_reward']\n",
    "\n",
    "        if self.maze_type not in env_types:\n",
    "            raise Exception(f\"Environment Type '{self.maze_type}' Not Recognized. \\nOptions are: {env_types} \\nDefault is Open Field (maze_type = 'none')\")\n",
    "\n",
    "        grid = np.zeros((self.r,self.c), dtype=int)\n",
    "\n",
    "        # set up obstables for different grid types\n",
    "        if self.maze_type == 'bar':\n",
    "            space = 2\n",
    "            self.rho = 0\n",
    "            for i in range(self.c-(2*space)):\n",
    "                grid[self.barheight][i+space] = 1\n",
    "\n",
    "        elif self.maze_type == 'room':\n",
    "            self.rho = 0\n",
    "            vwall = int(self.c/2)\n",
    "            hwall = int(self.r/2)\n",
    "\n",
    "            #make walls\n",
    "            for i in range(self.c):\n",
    "                grid[vwall][i] = 1\n",
    "            for i in range(self.r):\n",
    "                grid[i][hwall] = 1\n",
    "\n",
    "            # make doors\n",
    "            self.doors = []\n",
    "            self.doors.append((vwall, np.random.choice(np.arange(0,vwall))))\n",
    "            self.doors.append((vwall, np.random.choice(np.arange(vwall+1, self.c))))\n",
    "\n",
    "            self.doors.append((np.random.choice(np.arange(0,hwall)), hwall))\n",
    "            self.doors.append((np.random.choice(np.arange(hwall+1, self.r)),hwall))\n",
    "            for i in self.doors:\n",
    "                grid[i] = 0\n",
    "\n",
    "        elif self.maze_type == 'tmaze':\n",
    "            self.rho = 0\n",
    "            self.possible_ports = []\n",
    "            grid = np.ones((self.r, self.c), dtype=int)\n",
    "            h1, v1 = int(self.c/2), 0\n",
    "            if h1%2==0:\n",
    "                for i in range(self.c):\n",
    "                    grid[v1][i] = 0\n",
    "                    if i == 0:\n",
    "                        self.possible_ports.append((i,v1))\n",
    "                    elif i == self.c-1:\n",
    "                        self.possible_ports.append((i,v1))\n",
    "            else:\n",
    "                for i in range(self.c):\n",
    "                    grid[v1][i] = 0\n",
    "                    if i == 0:\n",
    "                        self.possible_ports.append((i,v1))\n",
    "                    elif i == self.c-1:\n",
    "                        self.possible_ports.append((i,v1))\n",
    "\n",
    "            if self.r > int(self.c/2):\n",
    "                for i in range(self.r):\n",
    "                    grid[i][h1] = 0\n",
    "                    if i == self.r-1:\n",
    "                        self.possible_ports.append((h1,i))\n",
    "            else:\n",
    "                for i in range(self.r):\n",
    "                    grid[i][h1] = 0\n",
    "                    if i == self.r-1:\n",
    "                        self.possible_ports.append((h1,i))\n",
    "\n",
    "        if self.obstacles_list is None:\n",
    "            if self.rho != 0:\n",
    "                maze = np.vstack([[np.random.choice([0,1], p = [1-self.rho, self.rho]) for _ in range(self.c)] for _ in range(self.r)])\n",
    "                grid = grid + maze\n",
    "                for reward_loc in self.rewards:\n",
    "                    if grid[reward_loc[1], reward_loc[0]] == 1:\n",
    "                        grid[reward_loc[1], reward_loc[0]] = 0\n",
    "\n",
    "            obstacles = list(zip(np.where(grid==1)[0], np.where(grid==1)[1]))\n",
    "            self.obstacle2D = obstacles\n",
    "            self.obstacle = [self.twoD2oneD((r,c)) for r,c in obstacles]\n",
    "\n",
    "        else:\n",
    "            for reward_loc in self.rewards:\n",
    "                if reward_loc in self.obstacles_list:\n",
    "                    self.obstacles_list.remove(reward_loc)\n",
    "            if isinstance(self.obstacles_list, tuple):\n",
    "                self.obstacle2D = [self.obstacles_list]\n",
    "                self.obstacle = [self.twoD2oneD(self.obstacles_list)]\n",
    "            else:\n",
    "                self.obstacle2D = self.obstacles_list\n",
    "                self.obstacle = [self.twoD2oneD((r,c)) for r,c in self.obstacles_list]\n",
    "                for coord in self.obstacles_list:\n",
    "                    grid[coord] = 1\n",
    "\n",
    "        if bound:\n",
    "            grid_bound = np.ones((self.r+2, self.c+2), dtype=int)\n",
    "            grid_bound[1:-1][:,1:-1] = grid\n",
    "            grid = grid_bound\n",
    "\n",
    "        # lists of tuples storing locations of open grid space and obstacles (unusable grid space)\n",
    "        useable_grid = list(zip(np.where(grid==0)[0], np.where(grid==0)[1]))\n",
    "        obstacles = list(zip(np.where(grid==1)[0], np.where(grid==1)[1]))\n",
    "\n",
    "        return grid, useable_grid, obstacles\n",
    "\n",
    "    def buildRewardFunction(self):\n",
    "        if self.rwd_action in self.action_list:\n",
    "            self.R = self.step_penalization*np.ones((self.nstates, len(self.action_list)))\n",
    "            action = self.action_list.index(self.rwd_action)\n",
    "            for r,c in list(self.rewards.keys()):\n",
    "                self.R[self.twoD2oneD((r,c)), action] = self.rewards[(r,c)]\n",
    "        else:\n",
    "            # specify reward function\n",
    "            self.R = self.step_penalization*np.ones((self.nstates,))  # rewards received upon leaving state\n",
    "            for r,c in list(self.rewards.keys()):\n",
    "                self.R[self.twoD2oneD((r,c))] = self.rewards[(r,c)]\n",
    "\n",
    "    def buildTransitionMatrix(self):\n",
    "        # initialize\n",
    "        self.P = np.zeros((len(self.action_list), self.nstates, self.nstates))  # down, up, right, left, jump, poke\n",
    "\n",
    "        # add neighbor connections and jumps, remove for endlines\n",
    "        self.P[0, list(range(0, self.nstates-self.shape[1])), list(range(self.shape[1], self.nstates))] = 1     # down\n",
    "        self.P[1, list(range(self.shape[1], self.nstates)), list(range(0, self.nstates-self.shape[1]))] = 1  \t# up\n",
    "\n",
    "        self.P[2, list(range(0, self.nstates-1)), list(range(1, self.nstates))] = 1  \t\t\t\t\t\t\t# right\n",
    "        self.P[3, list(range(1, self.nstates)), list(range(0, self.nstates-1))] = 1  \t\t\t\t\t\t\t# left\n",
    "        if len(self.action_list) > 4:\n",
    "            self.P[4, self.jump_from, self.jump_to] = 1\t\t\t\t\t\t\t\t\t\t\t\t# jump\n",
    "\n",
    "        # remove select states\n",
    "        endlines = list(range(self.shape[1]-1,self.nstates-self.shape[1],self.shape[1]))\n",
    "        endlines2 = [x+1 for x in endlines]\n",
    "        self.P[2, endlines, endlines2] = 0\t# remove transitions at the end of the grid\n",
    "        self.P[3, endlines2, endlines] = 0\n",
    "        for i in range(4):\n",
    "            self.P[i, :, self.obstacle] = 0  \t# remove transitions into obstacles\n",
    "            self.P[i, self.obstacle, :] = 0  \t# remove transitions from obstacles\n",
    "            self.P[i, self.terminal, :] = 0  \t# remove transitions from terminal states\n",
    "            if len(self.action_list) >4:\n",
    "                self.P[i, self.jump_from, :] = 0 \t# remove neighbor transitions from jump states\n",
    "\n",
    "        if len(self.action_list) >5:\n",
    "            # poke should make no transitions between states so everything stays 0\n",
    "            self.P[5, list(range(0, self.nstates)), list(range(0, self.nstates))] = 1\n",
    "\n",
    "    def remapTransitionMatrix(self):\n",
    "        oldP = self.P\n",
    "\n",
    "        # initalize\n",
    "        self.P = np.zeros((len(self.action_list), self.nstates, self.nstates))  # down, up, right, left, jump, poke\n",
    "\n",
    "        for x in range(oldP.shape[0]):\n",
    "            col = (x + 1) % oldP.shape[0]\n",
    "            self.P[col, :, :] = oldP[x, :, :]\n",
    "\n",
    "        print(\"transition probabilities remapped\")\n",
    "\n",
    "    def get_random_start_location(self):\n",
    "        get_start = np.random.choice(len(self.useable))\n",
    "        start_r = self.useable[get_start][0]\n",
    "        start_c = self.useable[get_start][1]\n",
    "        return (start_r, start_c)\n",
    "\n",
    "    def get_start_location(self, around_reward, **kwargs):\n",
    "        if around_reward:\n",
    "            radius = kwargs.get('rad', 5)\n",
    "            # pick starting location for agent in radius around reward location\n",
    "            start_buffer = radius  # radius around reward\n",
    "            starting_reward = list(self.rewards.keys())[np.random.choice(np.arange(len(self.rewards.keys())))]\n",
    "            get_start_loc = True\n",
    "            while get_start_loc:\n",
    "                buf_r = np.random.choice(np.arange(start_buffer))\n",
    "                start_r = starting_reward[0] + np.random.choice([-1, 1])*buf_r\n",
    "                if start_r < 0:\n",
    "                    start_r = 0\n",
    "                elif start_r > self.grid.shape[0] - 1:\n",
    "                    start_r = self.grid.shape[0] - 1\n",
    "\n",
    "                buf_c = np.random.choice(np.arange(start_buffer))\n",
    "                start_c = starting_reward[1] + np.random.choice([-1, 1])*buf_c\n",
    "                if start_c < 0:\n",
    "                    start_c = 0\n",
    "                elif start_c > self.grid.shape[1] - 1:\n",
    "                    start_c = self.grid.shape[1] - 1\n",
    "                if (start_r, start_c) in self.useable:\n",
    "                    get_start_loc = False\n",
    "        else: # pick a random starting location for agent within the useable spaces\n",
    "            get_start = np.random.choice(len(self.useable))\n",
    "            start_r = self.useable[get_start][0]\n",
    "            start_c = self.useable[get_start][1]\n",
    "\n",
    "        start_coord = (start_r, start_c)\n",
    "\n",
    "        return start_coord\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def get_actions(self):\n",
    "        slice_n_dice = self.P[:,self.state,:]\n",
    "        return np.any(slice_n_dice,axis=1)\n",
    "\n",
    "    def set_reward(self, rewards):\n",
    "        self.rewards = rewards\n",
    "\n",
    "        # recalculate reward function\n",
    "        self.buildRewardFunction()\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        action = self.action_list[action][0]\n",
    "        if len(self.R.shape) > 1:\n",
    "            reward = self.R[self.state,self.action_dict[action]]\n",
    "        else:\n",
    "            reward = self.R[self.state]\n",
    "        if self.finish_after_first_reward and reward in self.rewards.values():\n",
    "            self.done = True\n",
    "        \n",
    "        # check if this is a terminal state\n",
    "        if self.state in self.terminal:\n",
    "            self.done = True\n",
    "\n",
    "        # TODO: fix for kirth\n",
    "        if self.maze_type == 'tmaze':\n",
    "            if self.port_shift in ['equal', 'left', 'right']:\n",
    "                self.shift_rwd(self.port_shift)\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def reset_viewer(self, **kwargs):\n",
    "        trial = kwargs.get('trial', 'Grid World')\n",
    "        states = kwargs.get('states',False)\n",
    "        self.figure = plot_world(self, title=f'Trial {trial}',states=states)\n",
    "        ## test\n",
    "        fig, ax = self.figure\n",
    "        agent_r, agent_c = self.oneD2twoD(self.state)\n",
    "        patch = patches.Circle((agent_c + .5, agent_r + .5), 0.35,\n",
    "                               fc='b')  ## plot functions use x,y we use row(y), col(x)\n",
    "        ax.add_patch(patch)\n",
    "        fig.canvas.draw()\n",
    "        plt.show(block=False)\n",
    "        ## /test\n",
    "        \n",
    "    def render(self, pause_time=0.01, mode='human', **kwargs):\n",
    "        trial = kwargs.get('trial', None)\n",
    "        if mode == 'human':\n",
    "            agent_r, agent_c = self.oneD2twoD(self.state)\n",
    "            self.figure[1].patches[1].set_center([agent_r + 0.5, agent_c + 0.5])\n",
    "            self.figure[0].canvas.draw()\n",
    "            plt.pause(pause_time)\n",
    "\n",
    "            # TODO: fix this so render just updates the current_state patch\n",
    "            # TODO: base object to write current_state patch on top of\n",
    "        else:\n",
    "            assert 0, \"Render mode '%s' is not supported\" %mode\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "    def reset(self):\n",
    "        if self.random_start:\n",
    "            self.start = self.get_random_start_location()\n",
    "        else:\n",
    "            self.start = self.useable[0]\n",
    "        self.state = self.twoD2oneD(self.start)\n",
    "\n",
    "        self.done = False\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            move (str): one of ['D','U','R','L','J'] for down, up, right, left, and jump, respectively.\n",
    "        Returns:\n",
    "            tuple (a,b,c,d): a is the new state, b is the reward value, and c is a bool signifying terminal state, d is an empty dictionary to conform with OpenAi gym step function returning an 'info' parameter\n",
    "        \"\"\"\n",
    "\n",
    "        # check if move is valid, and then move\n",
    "        x = self.get_actions()\n",
    "        if not self.get_actions()[action]:\n",
    "            #raise Exception('Agent has tried an invalid action!')\n",
    "            pass\n",
    "        else:\n",
    "            transition_probs = self.P[action, self.state,:]\n",
    "            self.state = np.nonzero(transition_probs)[0][0]  # update to new state\n",
    "\n",
    "        reward = self.get_reward(action) ## self.done is set in this function\n",
    "\n",
    "        is_terminal = self.done\n",
    "\n",
    "        return self.state, reward, is_terminal, {}\n",
    "    \n",
    "def plot_world(world, **kwargs):\n",
    "    scale = kwargs.get('scale', 0.35)\n",
    "    title = kwargs.get('title', 'Grid World')\n",
    "    ax_labels = kwargs.get('ax_labels', False)\n",
    "    state_labels = kwargs.get('states', False)\n",
    "    invert_ = kwargs.get('invert', False)\n",
    "    if invert_:\n",
    "        cmap = 'bone'\n",
    "    else:\n",
    "        cmap = 'bone_r'\n",
    "    r,c = world.shape\n",
    "\n",
    "    fig = plt.figure(figsize=(c*scale, r*scale))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    gridMat = np.zeros(world.shape)\n",
    "    for i, j in world.obstacle2D:\n",
    "        gridMat[i, j] = 1.0\n",
    "    for i, j in world.terminal2D:\n",
    "        gridMat[i, j] = 0.2\n",
    "    ax.pcolor(gridMat, edgecolors='k', linewidths=0.75, cmap=cmap, vmin=0, vmax=1)\n",
    "\n",
    "    U = np.zeros((r, c))\n",
    "    V = np.zeros((r, c))\n",
    "    U[:] = np.nan\n",
    "    V[:] = np.nan\n",
    "\n",
    "    if len(world.action_list) >4 :\n",
    "        if world.jump is not None:\n",
    "            for (a, b) in world.jump.keys():\n",
    "                (a2, b2) = world.jump[(a, b)]\n",
    "                U[a, b] = (b2 - b)\n",
    "                V[a, b] = (a - a2)\n",
    "\n",
    "    C, R = np.meshgrid(np.arange(0, c) + 0.5, np.arange(0, r) + 0.5)\n",
    "    ax.quiver(C, R, U, V, scale=1, units='xy')\n",
    "\n",
    "    for rwd_loc in world.rewards.keys():\n",
    "        rwd_r, rwd_c = rwd_loc\n",
    "        if world.rewards[rwd_loc] < 0:\n",
    "            colorcode = 'red'\n",
    "        else:\n",
    "            colorcode = 'darkgreen'\n",
    "        ax.add_patch(plt.Rectangle((rwd_c, rwd_r), width=1, height=1, linewidth=2, facecolor=colorcode, alpha=0.5))\n",
    "\n",
    "    if state_labels:\n",
    "        for (i,j) in world.useable:\n",
    "            # i = row, j = col\n",
    "            ax.text(j+0.5,i+0.7, s=f'{world.twoD2oneD((i,j))}', ha='center')\n",
    "\n",
    "\n",
    "    #ax.set_xticks([np.arange(c) + 0.5, np.arange(c)])\n",
    "    #ax.set_yticks([np.arange(r) + 0.5, np.arange(r)])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    if not ax_labels:\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "    ax.set_title(title)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "class GridWorld_4rooms(GridWorld):\n",
    "    def __init__(self):\n",
    "        self.action_list = ['Down', 'Up', 'Right', 'Left']\n",
    "        self.rewarded_action = None\n",
    "        self.obstacles_list = [(0, 10), (1, 10), (2, 10), (3, 10), (5, 10), (6, 10), (7, 10), (8, 10), (9, 10), (10, 0), (10, 1), (10, 3), (10, 4), (10, 5), (10, 6), (10, 7), (10, 8), (10, 9), (10, 10), (10, 11), (10, 12), (10, 13), (10, 14), (10, 16), (10, 17), (10, 18), (10, 19), (11, 10), (12, 10), (14, 10), (15, 10), (16, 10), (17, 10), (18, 10), (19, 10)]\n",
    "        super().__init__(actionlist=self.action_list, rewarded_action=self.rewarded_action,obstacles=self.obstacles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gw_4rooms = GridWorld_4rooms()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
